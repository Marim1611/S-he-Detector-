{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import io,color\n",
    "from skimage.transform import resize\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from  LBP_descriptor import LocalBinaryPatterns\n",
    "import commonfunctions as cf\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import csv\n",
    "from cold_feature import cold_feature\n",
    "from skimage.feature import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our training data \n",
    "X_train: features of training data.\\\n",
    "Y_train: labels of training data (1-->F, 0--> M).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ICDAR LABELS \n",
    "labels_ICDAR=[]\n",
    "with open(\"our dataset/train_answers.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file, delimiter=',')\n",
    "    rows= np.array(list(csvreader))[1:].astype(float).astype(int)\n",
    "for row in rows:\n",
    "    labels_ICDAR.append(row[1])\n",
    "    \n",
    "def get_label_ICDAR(img):\n",
    "    if img[0]=='0':\n",
    "        if img[1]=='0': \n",
    "            return labels_ICDAR[int(img[2])-1]\n",
    "        else: \n",
    "            return labels_ICDAR[int(img[1:3])-1]\n",
    "    else: \n",
    "         return labels_ICDAR[int(img[0:3])-1]\n",
    "        \n",
    "\n",
    "\n",
    "def read_labels(path): \n",
    "    y=[]\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    for file in files:\n",
    "        if file[0]=='F':\n",
    "            y.append(0)\n",
    "        elif file[0]=='M':\n",
    "            y.append(1)\n",
    "        else: \n",
    "            y.append(get_label_ICDAR(file[1:4]))\n",
    "          \n",
    "    y=np.array(y).astype(float)\n",
    "    return y \n",
    "\n",
    "Y_train= read_labels(\"Training_data/\")\n",
    "Y_test= read_labels(\"Test_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLCM & HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM (image):\n",
    "\n",
    "    # convert image to gray\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    featureVector=[]\n",
    "    \n",
    "    # distances -> skipped pixels\n",
    "    glcm = greycomatrix(image, distances=[5], angles=[45], levels=256,\n",
    "                            symmetric=True, normed=True)\n",
    "    featureVector.append(greycoprops(glcm, 'dissimilarity')[0, 0])\n",
    "    featureVector.append(greycoprops(glcm, 'correlation')[0, 0])\n",
    "    featureVector.append(greycoprops(glcm, 'contrast')[0, 0])\n",
    "    featureVector.append(greycoprops(glcm, 'homogeneity')[0, 0])\n",
    "    return featureVector\n",
    "def HOG(img):\n",
    "    img = np.array(resize(img,(128,64))) \n",
    "    feature_vector, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3,3), visualize=True)\n",
    "    return feature_vector,hog_image    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBP Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object from LBP class to use it as our descriptor\n",
    "# takes 2 parameters: number of data (train + test ) and number of neighbors\n",
    "desc = LocalBinaryPatterns(24, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a new cold feature object\n",
    "cold = cold_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN HOG & GLCM\n",
    "X_train=[]\n",
    "HOG_train=[]\n",
    "GLCM_train=[]\n",
    " \n",
    "files = os.listdir(\"Training_data/\")\n",
    "for file in files:\n",
    "    # read the image\n",
    "    img = cv2.imread(\"Training_data/\"+file )\n",
    "    # ------------------- Convert into gray image -------------\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # threshold the grayscale image\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # ------------------- GLCM feature-----------------------\n",
    "    GLCM_train=GLCM(img)\n",
    "    #--------------------------------------------------------\n",
    "    # ------------------- HOG feature------------------------\n",
    "    HOG_train,hog_image=HOG(thresh)\n",
    "    # --------------------------------------------------------\n",
    "    #------------------- LBP feature------------------------\n",
    "    hist = desc.describe(thresh)\n",
    "    #-------------------- Cold feature ------------------------\n",
    "    cold_feature_vector = cold.getFeatureVectors(thresh)\n",
    "\n",
    "    # concatenate all the features in X_train   \n",
    "    feature_vector_temp=np.hstack((HOG_train, GLCM_train, hist, cold_feature_vector)).tolist()\n",
    "    X_train.append(feature_vector_temp)\n",
    "    # reset them for the next img\n",
    "    HOG_train=[]\n",
    "    GLCM_train=[]\n",
    "   \n",
    " \n",
    "#convert to numpy array\n",
    "X_train=np.array(X_train)\n",
    " \n",
    "#write feature vector of each image in external file\n",
    "with open('ALL_train.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "f.close()  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read feature vector of train data from the npy file \n",
    "with open('ALL_train.npy', 'rb') as f:\n",
    "    X_train = np.load(f,allow_pickle=True)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST HOG & GLCM\n",
    "X_test=[]\n",
    "files = os.listdir(\"Test_data/\")\n",
    "HOG_test=[]\n",
    "GLCM_test=[]\n",
    "for file in files:\n",
    "   \n",
    "    # read the image\n",
    "    img = cv2.imread(\"Test_data/\"+file )\n",
    "    # ------------------- Convert into gray image -------------\n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # threshold the grayscale image\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # ------------------- GLCM feature-----------------------\n",
    "    GLCM_train=GLCM(img)\n",
    "    #--------------------------------------------------------\n",
    "    # ------------------- HOG feature------------------------\n",
    "    HOG_train,hog_image=HOG(thresh)\n",
    "    # --------------------------------------------------------\n",
    "    #------------------- LBP feature------------------------\n",
    "    hist = desc.describe(thresh)\n",
    "    #-------------------- Cold feature ------------------------\n",
    "    cold_feature_vector = cold.getFeatureVectors(thresh)\n",
    "\n",
    "    # concatenate all the features in X_train   \n",
    "    feature_test_temp=np.hstack((HOG_train, GLCM_train, hist, cold_feature_vector)).tolist()\n",
    "    X_test.append(feature_test_temp)\n",
    "    # reset them for the next img\n",
    "    HOG_test=[]\n",
    "    GLCM_test=[]\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_votting = np.zeros(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.72972972972973 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf=RandomForestClassifier(n_estimators=2000)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")\n",
    "Y_votting = np.add(Y_Predicted, Y_votting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.97297297297297 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "clf=LinearSVC(C=300.0, random_state=42)\n",
    "clf.fit(X_train,Y_train )\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")\n",
    "Y_votting = np.add(Y_Predicted, Y_votting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.62162162162163 %\n"
     ]
    }
   ],
   "source": [
    "clf=AdaBoostClassifier(n_estimators=370)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")\n",
    "Y_votting = np.add(Y_Predicted, Y_votting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.56756756756756 %\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "max_accuracy_predicted = 0\n",
    "max_predicted_y = []\n",
    "for k in range(1,30):\n",
    "    clf=KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    Y_Predicted=clf.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(Y_test, Y_Predicted)*100\n",
    "    if accuracy > max_accuracy_predicted:\n",
    "        max_predicted_y = Y_Predicted\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(\"Accuracy:\",accuracies[np.argmax(accuracies)],\"%\")\n",
    "Y_votting = np.add(Y_Predicted, Y_votting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Votting system classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.32432432432432 %\n"
     ]
    }
   ],
   "source": [
    "Y_votting = np.where(Y_votting > 2, 1, 0)\n",
    "print(\"Accuracy:\", metrics.accuracy_score(Y_test, Y_votting)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.13513513513513 %\n"
     ]
    }
   ],
   "source": [
    "clf=GradientBoostingClassifier(n_estimators=120, learning_rate=1.0, max_depth=8,random_state=0)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2ab3825ac7005fb7b26f112e9c99ae62f464c629e30b0d534c3b931b6cbc3ff"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
