{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import io,color\n",
    "from skimage.transform import resize\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from  LBP_descriptor import LocalBinaryPatterns\n",
    "import commonfunctions as cf\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our training data \n",
    "X_train: features of training data.\\\n",
    "Y_train: labels of training data (1-->F, 0--> M).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=[]\n",
    "\n",
    "files = os.listdir(\"Training_data/preprocessed/\")\n",
    "\n",
    "for file in files:\n",
    "    if file[0]=='F':\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)\n",
    "\n",
    "Y_train=np.array(Y_train).astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOG feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG(img):\n",
    "    img = np.array(resize(io.imread(img),(128,64))) \n",
    "    feature_vector, hog_image = hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(5,5), visualize=True)\n",
    "    return feature_vector,hog_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LBP feature and histogram descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object from LBP class to use it as our descriptor\n",
    "# takes 2 parameters: number of data (train + test ) and number of neighbors\n",
    "desc = LocalBinaryPatterns(258, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save your time: \n",
    "# run this cell once and the features will be saved in external file so that you can read them by running the next cell.\n",
    "X_train=[]\n",
    "files = os.listdir(\"Training_data/preprocessed/\")\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    #------------------- HOG feature------------------------\n",
    "    #feature_vector,hog_image=HOG(\"Training_data/preprocessed/\"+file)\n",
    "    #--------------------------------------------------------\n",
    "    #X_train.append(feature_vector)\n",
    "    \n",
    "    #------------------- LBP feature------------------------\n",
    "    img = io.imread(\"Training_data/preprocessed/\"+file )\n",
    "    img = cf.downSize(img , 0.5)\n",
    "    hist = desc.describe(img)\n",
    "    X_train.append(hist)\n",
    "    #--------------------------------------------------------\n",
    "    \n",
    "X_train=np.array(X_train)\n",
    "\n",
    "#write feature vector of each image in external file\n",
    "with open('LBP_descriptor.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "f.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.85356828e-02 4.79450421e-03 8.80866623e-04 ... 1.70380391e-06\n",
      "  8.28336644e-01 1.27514389e-01]\n",
      " [1.32188627e-02 3.19657468e-03 6.18297702e-04 ... 0.00000000e+00\n",
      "  8.90632179e-01 7.75707010e-02]\n",
      " [9.01382887e-03 2.23941227e-03 3.61279170e-04 ... 7.69230769e-05\n",
      "  8.35508211e-01 1.00595506e-01]\n",
      " ...\n",
      " [9.31152050e-03 1.87066059e-03 4.61994671e-04 ... 0.00000000e+00\n",
      "  9.18829805e-01 5.49511026e-02]\n",
      " [1.72780876e-02 3.27640293e-03 6.31753224e-04 ... 0.00000000e+00\n",
      "  8.30305275e-01 1.16662310e-01]\n",
      " [2.34644685e-02 4.53319049e-03 1.07378090e-03 ... 0.00000000e+00\n",
      "  8.10999683e-01 1.27926239e-01]]\n"
     ]
    }
   ],
   "source": [
    "# read feature vector of training data from the npy file \n",
    "with open('LBP_descriptor.npy', 'rb') as f:\n",
    "    X_train = np.load(f)\n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to save your time: \n",
    "# run this cell once and the features will be saved in external files so that you can read them by running the next cell.\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "\n",
    "files = os.listdir(\"Test_data/preprocessed/\")\n",
    "\n",
    "for file in files:\n",
    "    if file[0]=='F':\n",
    "        Y_test.append(1)\n",
    "    else:\n",
    "        Y_test.append(0)\n",
    "    #------------------- HOG feature------------------------\n",
    "    #feature_vector,hog_image=HOG(\"our dataset/test/\"+file)\n",
    "    #X_test.append(feature_vector)\n",
    "    \n",
    "    #------------------- LBP feature------------------------\n",
    "    img = io.imread(\"Test_data/preprocessed/\" +file )\n",
    "    img = cf.downSize(img , 0.5)\n",
    "    hist = desc.describe(img)\n",
    "\n",
    "    X_test.append(hist)\n",
    "    #--------------------------------------------------------\n",
    "\n",
    "    \n",
    "Y_test=np.array(Y_test)\n",
    "X_test=np.array(X_test)\n",
    "\n",
    "#write feature vector of test data in external file\n",
    "with open('X_test.npy', 'wb') as f:\n",
    "    np.save(f, X_test)\n",
    "f.close()   \n",
    "#write labels of test data in external file\n",
    "with open('Y_test.npy', 'wb') as f:\n",
    "    np.save(f, Y_test)\n",
    "f.close()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read feature vector of test data from the npy file \n",
    "with open('X_test.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "f.close()  \n",
    "# read labels of test data from the npy file \n",
    "with open('Y_test.npy', 'rb') as f:\n",
    "    Y_test = np.load(f)\n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.61538461538461 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf=RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 71.15384615384616 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "clf=LinearSVC(C=100.0, random_state=42)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 53.84615384615385 %\n"
     ]
    }
   ],
   "source": [
    "clf=AdaBoostClassifier(n_estimators=500)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.53846153846154 %\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "for k in range(1,30):\n",
    "    clf=KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    Y_Predicted=clf.predict(X_test)\n",
    "    accuracies.append(metrics.accuracy_score(Y_test, Y_Predicted)*100)\n",
    "\n",
    "print(\"Accuracy:\",accuracies[np.argmax(accuracies)],\"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3a52463084db90f96d29dcfcfd9bf276dba3c521d76c4c38c835392b64a093b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
