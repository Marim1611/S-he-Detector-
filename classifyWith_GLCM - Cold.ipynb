{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import io,color\n",
    "from skimage.transform import resize\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from  LBP_descriptor import LocalBinaryPatterns\n",
    "import commonfunctions as cf\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import csv\n",
    "from cold_feature import cold_feature\n",
    "from skimage.feature import greycomatrix, greycoprops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get our training data \n",
    "X_train: features of training data.\\\n",
    "Y_train: labels of training data (1-->F, 0--> M).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ICDAR LABELS \n",
    "labels_ICDAR=[]\n",
    "with open(\"our dataset/train_answers.csv\", 'r') as file:\n",
    "    csvreader = csv.reader(file, delimiter=',')\n",
    "    rows= np.array(list(csvreader))[1:].astype(float).astype(int)\n",
    "for row in rows:\n",
    "    labels_ICDAR.append(row[1])\n",
    "    \n",
    "def get_label_ICDAR(img):\n",
    "    if img[0]=='0':\n",
    "        if img[1]=='0': \n",
    "            return labels_ICDAR[int(img[2])-1]\n",
    "        else: \n",
    "            return labels_ICDAR[int(img[1:3])-1]\n",
    "    else: \n",
    "         return labels_ICDAR[int(img[0:3])-1]\n",
    "        \n",
    "\n",
    "\n",
    "def read_labels(path): \n",
    "    y=[]\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    for file in files:\n",
    "        if file[0]=='F':\n",
    "            y.append(0)\n",
    "        elif file[0]=='M':\n",
    "            y.append(1)\n",
    "        else: \n",
    "            y.append(get_label_ICDAR(file[1:4]))\n",
    "          \n",
    "    y=np.array(y).astype(float)\n",
    "    return y \n",
    "\n",
    "Y_train= read_labels(\"Training_data/\")\n",
    "Y_test= read_labels(\"Test_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLCM feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GLCM (image):\n",
    "\n",
    "    # convert image to gray\n",
    "    image= cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    featureVector=[]\n",
    "    \n",
    "    # distances -> skipped pixels\n",
    "    glcm = greycomatrix(image, distances=[4], angles=[0], levels=256,\n",
    "                            symmetric=True, normed=True)\n",
    "    featureVector.append(greycoprops(glcm, 'dissimilarity')[0, 0])\n",
    "    featureVector.append(greycoprops(glcm, 'correlation')[0, 0])\n",
    "    featureVector.append(greycoprops(glcm, 'contrast')[0, 0])\n",
    "    featureVector.append(greycoprops(glcm, 'homogeneity')[0, 0])\n",
    "    return featureVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a new cold feature object\n",
    "cold = cold_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\feature\\__init__.py:35: skimage_deprecation: Function ``greycomatrix`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycomatrix`` instead.\n",
      "  removed_version='1.0')\n",
      "c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n",
      "c:\\Users\\omara\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\feature\\__init__.py:42: skimage_deprecation: Function ``greycoprops`` is deprecated and will be removed in version 1.0. Use ``skimage.feature.graycoprops`` instead.\n",
      "  removed_version='1.0')\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\study affairs\\syllabus\\3rd year\\2nd semester\\neural networks\\Project\\Handwriting-detection\\classifyWith_GLCM - Cold.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000007?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(img)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000007?line=8'>9</a>\u001b[0m \u001b[39m#-------------------- Cold feature ------------------------\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000007?line=9'>10</a>\u001b[0m cold_feature_vector \u001b[39m=\u001b[39m cold\u001b[39m.\u001b[39;49mgetFeatureVectors(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000007?line=10'>11</a>\u001b[0m \u001b[39m# Append the cold and glcm together in one vector\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000007?line=11'>12</a>\u001b[0m X_train\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mappend(cold_feature_vector, glcm))\n",
      "File \u001b[1;32md:\\study affairs\\syllabus\\3rd year\\2nd semester\\neural networks\\Project\\Handwriting-detection\\cold_feature.py:121\u001b[0m, in \u001b[0;36mcold_feature.getFeatureVectors\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=114'>115</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetFeatureVectors\u001b[39m(\u001b[39mself\u001b[39m, image):\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=115'>116</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=116'>117</a>\u001b[0m \u001b[39m    This function implements the whole process to \u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=117'>118</a>\u001b[0m \u001b[39m    extract the feature vector for the image provided \u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=118'>119</a>\u001b[0m \u001b[39m    by the constructor\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=119'>120</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=120'>121</a>\u001b[0m     poly_approximated_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mPolyApproxMethod(image)\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=121'>122</a>\u001b[0m     distribution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution(poly_approximated_image)\n\u001b[0;32m    <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=122'>123</a>\u001b[0m     feature_vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalculateFeatureVector(distribution)\n",
      "File \u001b[1;32md:\\study affairs\\syllabus\\3rd year\\2nd semester\\neural networks\\Project\\Handwriting-detection\\cold_feature.py:31\u001b[0m, in \u001b[0;36mcold_feature.PolyApproxMethod\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=20'>21</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=21'>22</a>\u001b[0m \u001b[39mThis function calculates the approximated shape to the image\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=22'>23</a>\u001b[0m \u001b[39mby representing it with minimum points w.r.t an accuracy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=27'>28</a>\u001b[0m \u001b[39mimage -- The needed image\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=28'>29</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=29'>30</a>\u001b[0m approximated_images \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=30'>31</a>\u001b[0m contours, hierarchy \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mfindContours(image, cv2\u001b[39m.\u001b[39;49mRETR_TREE, cv2\u001b[39m.\u001b[39;49mCHAIN_APPROX_SIMPLE)\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=31'>32</a>\u001b[0m \u001b[39mfor\u001b[39;00m contour \u001b[39min\u001b[39;00m contours:\n\u001b[0;32m     <a href='file:///d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/cold_feature.py?line=32'>33</a>\u001b[0m     percentage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoly_approx_method_accuracy \u001b[39m*\u001b[39m cv2\u001b[39m.\u001b[39marcLength(contour, \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "files = os.listdir(\"Training_data/\")\n",
    "for file in files:\n",
    "    # read the image\n",
    "    img = cv2.imread(\"Training_data/\" + file)\n",
    "    # ------------------- GLCM feature ------------------------\n",
    "    glcm = GLCM(img)\n",
    "    print(img)\n",
    "    #-------------------- Cold feature ------------------------\n",
    "    cold_feature_vector = cold.getFeatureVectors(img)\n",
    "    # Append the cold and glcm together in one vector\n",
    "    X_train.append(np.append(cold_feature_vector, glcm))\n",
    "\n",
    "#convert to numpy array\n",
    "X_train=np.array(X_train)\n",
    "#write feature vector of each image in external file\n",
    "with open('GLCM_COLD_train.npy', 'wb') as f:\n",
    "    np.save(f, X_train)\n",
    "f.close()  \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GLCM_COLD_train.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\study affairs\\syllabus\\3rd year\\2nd semester\\neural networks\\Project\\Handwriting-detection\\classifyWith_GLCM - Cold.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39m# Read feature vector of train data from the npy file \u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000006?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mGLCM_COLD_train.npy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000006?line=2'>3</a>\u001b[0m     X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(f,allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/study%20affairs/syllabus/3rd%20year/2nd%20semester/neural%20networks/Project/Handwriting-detection/classifyWith_GLCM%20-%20Cold.ipynb#ch0000006?line=3'>4</a>\u001b[0m f\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GLCM_COLD_train.npy'"
     ]
    }
   ],
   "source": [
    "# Read feature vector of train data from the npy file \n",
    "with open('GLCM_COLD_train.npy', 'rb') as f:\n",
    "    X_train = np.load(f,allow_pickle=True)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test dataset\n",
    "X_test=[]\n",
    "files = os.listdir(\"Test_data/\")\n",
    "\n",
    "for file in files:\n",
    "   \n",
    "    # read te img\n",
    "    img = cv2.imread(\"Test_data/\" +file )\n",
    "    # ------------------- GLCM feature ------------------------\n",
    "    glcm = GLCM(img)\n",
    "    #-------------------- Cold feature ------------------------\n",
    "    cold.set_image(img)\n",
    "    cold_feature_vector = cold.getFeatureVectors()\n",
    "    # Append the cold and glcm together in one vector\n",
    "    X_train.append(np.append(cold_feature_vector, glcm))    \n",
    "    \n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.692307692307686 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf=RandomForestClassifier(n_estimators=2000)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.51282051282051 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "clf=LinearSVC(C=100.0, random_state=42)\n",
    "clf.fit(X_train,Y_train )\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 52.56410256410257 %\n"
     ]
    }
   ],
   "source": [
    "clf=AdaBoostClassifier(n_estimators=320)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_Predicted=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_Predicted)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.51282051282051 %\n"
     ]
    }
   ],
   "source": [
    "accuracies=[]\n",
    "for k in range(1,160):\n",
    "    clf=KNeighborsClassifier(n_neighbors = k)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    Y_Predicted=clf.predict(X_test)\n",
    "    accuracies.append(metrics.accuracy_score(Y_test, Y_Predicted)*100)\n",
    "\n",
    "print(\"Accuracy:\",accuracies[np.argmax(accuracies)],\"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ce1aa5045122ce61d81150741fc545f0705456a83bb0ce116eee68d33a445e8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
