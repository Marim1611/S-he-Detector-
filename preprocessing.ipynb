{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import fftpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropTxtOnly(image):\n",
    "    # cv2.imshow(image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    \n",
    "    img = image[30:-450,20:-20] # Perform pre-cropping\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = 255*(gray < 90).astype(np.uint8) # To invert the text to white\n",
    "    gray = cv2.morphologyEx(gray, cv2.MORPH_OPEN, np.ones((2, 2), dtype=np.uint8)) # Perform noise filtering\n",
    "\n",
    "    coords = cv2.findNonZero(gray) # Find all non-zero points (text)\n",
    "    x, y, w, h = cv2.boundingRect(coords) # Find minimum spanning bounding box\n",
    "    rect = img[y:y+h, x:x+w] # Crop the image - note we do this on the original image\n",
    "    return rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getLineTextFromImg(dataSrc,dataDest, target):\n",
    "    \n",
    "    genders=[\"Female\", \"Male\"]\n",
    "\n",
    "    for gender in genders:\n",
    "        files = os.listdir(\"our dataset/\"+dataSrc+\"/\" +gender)\n",
    "\n",
    "        for file in files:\n",
    "\n",
    "            foldername=file.split('.')[0]\n",
    "            if not os.path.exists(\"preprocessed/\"+dataDest+'/'+gender+'/'+foldername):\n",
    "                os.makedirs(\"preprocessed/\"+dataDest+'/'+gender+'/'+foldername)\n",
    "\n",
    "            if not os.path.exists(target+\"/preprocessed/\"):\n",
    "                os.makedirs(target+\"/preprocessed/\")\n",
    "\n",
    "            # load image\n",
    "            img = cv2.imread(\"our dataset/\"+dataSrc+\"/\" + gender + \"/\" + file )\n",
    "\n",
    "            #crop the text only from the image\n",
    "            cropped_img=cropTxtOnly(img)\n",
    "            cv2.imwrite(\"preprocessed/\"+dataDest+'/'+gender+'/'+foldername+'/'+\"cropped.png\", cropped_img) # Save the image\n",
    "\n",
    "            # convert to gray\n",
    "            gray = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # threshold the grayscale image\n",
    "            thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "            # use morphology erode to blur horizontally\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (200, 3))\n",
    "            morph = cv2.morphologyEx(thresh, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "            # use morphology open to remove thin lines from dotted lines\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 17))\n",
    "            morph = cv2.morphologyEx(morph, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "            # find contours\n",
    "            cntrs = cv2.findContours(morph, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cntrs = cntrs[0] if len(cntrs) == 2 else cntrs[1]\n",
    "\n",
    "            i=0\n",
    "            thresh_result = thresh.copy()\n",
    "            for c in cntrs:\n",
    "                box = cv2.boundingRect(c)\n",
    "                x,y,w,h = box\n",
    "                cv2.imwrite(\"preprocessed/\"+dataDest+'/'+gender+'/'+foldername + \"/\" + foldername + \"-\"+str(i)+\".jpg\", thresh_result[ y:y+h , x:x+w ] )\n",
    "                i+=1\n",
    "\n",
    "\n",
    "            # write result to disk\n",
    "\n",
    "            cv2.imwrite(target+\"/preprocessed/\"+foldername+\".jpg\", thresh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8529a815f964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgetLineTextFromImg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Training_data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-9fedf10ba474>\u001b[0m in \u001b[0;36mgetLineTextFromImg\u001b[1;34m(dataSrc, dataDest, target)\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;31m# use morphology erode to blur horizontally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetStructuringElement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPH_RECT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mmorph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmorphologyEx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthresh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMORPH_DILATE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;31m# use morphology open to remove thin lines from dotted lines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "getLineTextFromImg(\"train\",\"train\",\"Training_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getLineTextFromImg(\"test\",\"test\",\"Test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cannyEdgeDetection(image):\n",
    "    cv2.Canny(image,50,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commonfunctions as cf # this a custom module found the commonfunctions.py\n",
    "\n",
    "# This function applies a filter to an image in the frequency domain\n",
    "# and plots multiple images describing the process\n",
    "def apply_filter_in_freq(img, f):\n",
    "    img_in_freq = fftpack.fft2(img)\n",
    "    \n",
    "    # we supply the img shape here to make both the filter and img have the same shape to be able to multiply\n",
    "    filter_in_freq = fftpack.fft2(f, img.shape)\n",
    "    filtered_img_in_freq = np.multiply(img_in_freq, filter_in_freq)\n",
    "    filtered_img = fftpack.ifft2(filtered_img_in_freq)\n",
    "\n",
    "    return filtered_img\n",
    "   \n",
    "def LPF(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    f1=np.array([\n",
    "    [1,2,1],\n",
    "    [2,4,2],\n",
    "    [1,2,1]\n",
    "    ])\n",
    "\n",
    "    filtered_img = apply_filter_in_freq(gray, f1)\n",
    "    cf.show_images([np.abs(filtered_img)], ['Filtered Image'])\n",
    "    # cv2.imwrite(\"F1/LPF.png\",np.int64( np.abs(filtered_img) ) )\n",
    "    # cv2.imshow(\"filtered_img\",np.int8( np.abs(filtered_img) ) )\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# img = cv2.imread(\"preprocessed/F1/preprocessed.png\")\n",
    "# LPF(img)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3a52463084db90f96d29dcfcfd9bf276dba3c521d76c4c38c835392b64a093b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
